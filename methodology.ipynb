{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4deffd2c",
   "metadata": {},
   "source": [
    "<h1> Bike share data analysis sample case </h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c8c6c3",
   "metadata": {},
   "source": [
    "<h3>Author: Luis Gonzalez </h3>\n",
    "<p></p>\n",
    "Email: luisf.gonzalezv@yahoo.com\n",
    "<p></p>\n",
    "Date: 18/12/2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7132be74",
   "metadata": {},
   "source": [
    "This notebook contains the step-by-step process of a data analysis sample case made on free access divvy data from the year 2022, a bike share company from Chicago. \n",
    "<p></p>\n",
    "the original dataset is avaiblable at: https://divvy-tripdata.s3.amazonaws.com/index.html .\n",
    "The purpose of this data analysis, as stated in the main report, is to identify the main differences between casual customers and members, as well as finding possible insights on how to market membserhips for casual bike share customers.  \n",
    "\n",
    "<h3>Step 1: Data Collection </h3>\n",
    "<p></p>\n",
    "From the webpage shown above, we can see the data is downloadable by month, as well as by quarter, and on the moment this report was made, the first available dataset was for april 2020 and the last dataset was from november 2023. We choose to analyze 2022, as the last complete year available. \n",
    "<p></p>\n",
    "The data is available as a downloadable zip folder. For convenience, it´s best to simply download these zip folders, and gather the .csv files from every month. We also name each file with the same format, as it will be useful for the data handling process later on. \n",
    "<p></p>\n",
    "We name the file \"2022mo-divvy-tripdata.csv\", where mo is a number from 01 to 12 (the 0 is important) for each month of the year."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da8306d",
   "metadata": {},
   "source": [
    "<h3> Step 2: Data Understanding </h3>\n",
    "<p></p>\n",
    " Before wrangling the data, it´s important to understand its contents and properties. For exploratory analysis of the files, we can use the pandas library. We now create a list with all the file names in the mentioned format, which makes it easier for looping. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8f4dc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "files=list()\n",
    "while i<13:\n",
    "    if i<10:\n",
    "        fname=\"20220\"+str(i)+\"-divvy-tripdata.csv\"\n",
    "    else :\n",
    "        fname=\"2022\"+str(i)+\"-divvy-tripdata.csv\"\n",
    "    files.append(fname)\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ad2cab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len (files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8c5fcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required library\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38f23dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ride_id', 'rideable_type', 'started_at', 'ended_at',\n",
       "       'start_station_name', 'start_station_id', 'end_station_name',\n",
       "       'end_station_id', 'start_lat', 'start_lng', 'end_lat', 'end_lng',\n",
       "       'member_casual'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let´s check the columns for this dataset\n",
    "df = pd.read_csv(files[0], header=0)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b0630bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ride_id</th>\n",
       "      <th>rideable_type</th>\n",
       "      <th>started_at</th>\n",
       "      <th>ended_at</th>\n",
       "      <th>start_station_name</th>\n",
       "      <th>start_station_id</th>\n",
       "      <th>end_station_name</th>\n",
       "      <th>end_station_id</th>\n",
       "      <th>start_lat</th>\n",
       "      <th>start_lng</th>\n",
       "      <th>end_lat</th>\n",
       "      <th>end_lng</th>\n",
       "      <th>member_casual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C2F7DD78E82EC875</td>\n",
       "      <td>electric_bike</td>\n",
       "      <td>2022-01-13 11:59:47</td>\n",
       "      <td>2022-01-13 12:02:44</td>\n",
       "      <td>Glenwood Ave &amp; Touhy Ave</td>\n",
       "      <td>525</td>\n",
       "      <td>Clark St &amp; Touhy Ave</td>\n",
       "      <td>RP-007</td>\n",
       "      <td>42.012800</td>\n",
       "      <td>-87.665906</td>\n",
       "      <td>42.012560</td>\n",
       "      <td>-87.674367</td>\n",
       "      <td>casual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A6CF8980A652D272</td>\n",
       "      <td>electric_bike</td>\n",
       "      <td>2022-01-10 08:41:56</td>\n",
       "      <td>2022-01-10 08:46:17</td>\n",
       "      <td>Glenwood Ave &amp; Touhy Ave</td>\n",
       "      <td>525</td>\n",
       "      <td>Clark St &amp; Touhy Ave</td>\n",
       "      <td>RP-007</td>\n",
       "      <td>42.012763</td>\n",
       "      <td>-87.665967</td>\n",
       "      <td>42.012560</td>\n",
       "      <td>-87.674367</td>\n",
       "      <td>casual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BD0F91DFF741C66D</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2022-01-25 04:53:40</td>\n",
       "      <td>2022-01-25 04:58:01</td>\n",
       "      <td>Sheffield Ave &amp; Fullerton Ave</td>\n",
       "      <td>TA1306000016</td>\n",
       "      <td>Greenview Ave &amp; Fullerton Ave</td>\n",
       "      <td>TA1307000001</td>\n",
       "      <td>41.925602</td>\n",
       "      <td>-87.653708</td>\n",
       "      <td>41.925330</td>\n",
       "      <td>-87.665800</td>\n",
       "      <td>member</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CBB80ED419105406</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2022-01-04 00:18:04</td>\n",
       "      <td>2022-01-04 00:33:00</td>\n",
       "      <td>Clark St &amp; Bryn Mawr Ave</td>\n",
       "      <td>KA1504000151</td>\n",
       "      <td>Paulina St &amp; Montrose Ave</td>\n",
       "      <td>TA1309000021</td>\n",
       "      <td>41.983593</td>\n",
       "      <td>-87.669154</td>\n",
       "      <td>41.961507</td>\n",
       "      <td>-87.671387</td>\n",
       "      <td>casual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DDC963BFDDA51EEA</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2022-01-20 01:31:10</td>\n",
       "      <td>2022-01-20 01:37:12</td>\n",
       "      <td>Michigan Ave &amp; Jackson Blvd</td>\n",
       "      <td>TA1309000002</td>\n",
       "      <td>State St &amp; Randolph St</td>\n",
       "      <td>TA1305000029</td>\n",
       "      <td>41.877850</td>\n",
       "      <td>-87.624080</td>\n",
       "      <td>41.884621</td>\n",
       "      <td>-87.627834</td>\n",
       "      <td>member</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ride_id  rideable_type           started_at             ended_at  \\\n",
       "0  C2F7DD78E82EC875  electric_bike  2022-01-13 11:59:47  2022-01-13 12:02:44   \n",
       "1  A6CF8980A652D272  electric_bike  2022-01-10 08:41:56  2022-01-10 08:46:17   \n",
       "2  BD0F91DFF741C66D   classic_bike  2022-01-25 04:53:40  2022-01-25 04:58:01   \n",
       "3  CBB80ED419105406   classic_bike  2022-01-04 00:18:04  2022-01-04 00:33:00   \n",
       "4  DDC963BFDDA51EEA   classic_bike  2022-01-20 01:31:10  2022-01-20 01:37:12   \n",
       "\n",
       "              start_station_name start_station_id  \\\n",
       "0       Glenwood Ave & Touhy Ave              525   \n",
       "1       Glenwood Ave & Touhy Ave              525   \n",
       "2  Sheffield Ave & Fullerton Ave     TA1306000016   \n",
       "3       Clark St & Bryn Mawr Ave     KA1504000151   \n",
       "4    Michigan Ave & Jackson Blvd     TA1309000002   \n",
       "\n",
       "                end_station_name end_station_id  start_lat  start_lng  \\\n",
       "0           Clark St & Touhy Ave         RP-007  42.012800 -87.665906   \n",
       "1           Clark St & Touhy Ave         RP-007  42.012763 -87.665967   \n",
       "2  Greenview Ave & Fullerton Ave   TA1307000001  41.925602 -87.653708   \n",
       "3      Paulina St & Montrose Ave   TA1309000021  41.983593 -87.669154   \n",
       "4         State St & Randolph St   TA1305000029  41.877850 -87.624080   \n",
       "\n",
       "     end_lat    end_lng member_casual  \n",
       "0  42.012560 -87.674367        casual  \n",
       "1  42.012560 -87.674367        casual  \n",
       "2  41.925330 -87.665800        member  \n",
       "3  41.961507 -87.671387        casual  \n",
       "4  41.884621 -87.627834        member  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "facec4f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103770, 13)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab496eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "classic_bike     55067\n",
       "electric_bike    47742\n",
       "docked_bike        961\n",
       "Name: rideable_type, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"rideable_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef485a9",
   "metadata": {},
   "source": [
    "From exploratory analysis of this dataset we conclude it contains 13 columns or fiels, with over 100 thousand observations for each month. To avoid making the code unnecessarily slow, we don´t open the other months, but they all contain the same columns, which is the most important thing. The columns contain the following information:\n",
    "- ride_id: A unique string for every distinct trip or observation. It can be used as a primary key if moved to a database.\n",
    "- rideable_type: the type of bike used, either classic, electric or docked.\n",
    "- started_at and ended_at: a datetime format value for when the trip started or ended.\n",
    "- start_station_name and end_station_name: String values for the location of each station where the trips took place.\n",
    "- start_station_id\tand end_station_id: Unique string values for each station name.\n",
    "- start_lat, start_lng, end_lat, end_lng: The spatial coordinates for each trip registered. \"Lat\" stands for latitude, and \"lng\" for longitude.\n",
    "- member_casual: Identifies each user as a member (i.e. with a subscription to the service) or a casual user.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de6d248",
   "metadata": {},
   "source": [
    "In order to know how many observations we really have, we can run the following cell of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0182ed4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In total, there are 5667717 observations for the annual dataset.\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for i in files:\n",
    "    df = pd.read_csv(i, header=0)\n",
    "    count=count+df.shape[0]\n",
    "print(\"In total, there are \"+str(count)+\" observations for the annual dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4dd4b3",
   "metadata": {},
   "source": [
    "We discover, the size of the combined dataset is quite extense, over 5 million obervations, each with 13 attributes. We want to use a data analysis method that is able to move through the dataset and make changes as fast as possible. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68265ac2",
   "metadata": {},
   "source": [
    "<h3>Step 3: Data Preparation</h3>\n",
    "<p></p>\n",
    "With the size of the dataset in mind, it´s a good idea to use an SQL database in conjucntion with python, for quick and effective handling of medium to large datasets. Python has a built-in library for this, using free-access sqlite3 software.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12348fd",
   "metadata": {},
   "source": [
    "Now we import the relevant modules for the entire process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b79fd136",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcb657a",
   "metadata": {},
   "source": [
    "Connect to an sqlite3 database, and create a cursor object. We then create empty table schemas, with the appropriate column formatting for efficient memory storage within the database. Notice that a separate table, stations, is created for storing the string values of each distinct station. This will help create quicker CRUD operations on the main table, total, as strings take up more space in general than other SQL data formats.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4dea9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('divvy_public.sqlite') \n",
    "cur = conn.cursor()\n",
    "conn = sqlite3.connect('divvy_public.sqlite') \n",
    "cur = conn.cursor() #file handle for the DB cursor object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8773576a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database and tables created successfully.\n"
     ]
    }
   ],
   "source": [
    "#  create table schemas\n",
    "cur.executescript('''DROP TABLE IF EXISTS stations;\n",
    "                  CREATE TABLE stations (\n",
    "                      station_id TINYTEXT NOT NULL PRIMARY KEY UNIQUE,\n",
    "                      station_name TINYTEXT,\n",
    "                      latitude REAL,\n",
    "                      longitude REAL, \n",
    "                      times_visited INTEGER DEFAULT 0);\n",
    "                  ''')\n",
    "                  \n",
    "cur.executescript('''DROP TABLE IF EXISTS total;\n",
    "                    CREATE TABLE total (\n",
    "                        ride_id TINYTEXT NOT NULL PRIMARY KEY UNIQUE,\n",
    "                        rideable_type TINYTEXT,\n",
    "                        started_at DATETIME,\n",
    "                        ended_at DATETIME,\n",
    "                        start_station_id TINYTEXT,\n",
    "                        end_station_id TINYTEXT,\n",
    "                        start_lat REAL,\n",
    "                        start_lng REAL,\n",
    "                        end_lat REAL,\n",
    "                        end_lng REAL,\n",
    "                        membership TINYTEXT,\n",
    "                        trip_duration INTEGER DEFAULT 0,\n",
    "                        trip_distance INTEGER DEFAULT 0\n",
    "                        );''')\n",
    "    \n",
    "print(\"Database and tables created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8155c1e8",
   "metadata": {},
   "source": [
    "Loop through each file in the files list. Then run a nested loop, where you loop through every line in each file, except for the first line (the headers). For each valid line, insert the record into our existing database. This cell of code can take several minutes to complete. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67427d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success. 103772 rows were processed for file 202201-divvy-tripdata.csv\n",
      "Success. 115611 rows were processed for file 202202-divvy-tripdata.csv\n",
      "Success. 284044 rows were processed for file 202203-divvy-tripdata.csv\n",
      "Success. 371251 rows were processed for file 202204-divvy-tripdata.csv\n",
      "Success. 634860 rows were processed for file 202205-divvy-tripdata.csv\n",
      "Success. 769206 rows were processed for file 202206-divvy-tripdata.csv\n",
      "Success. 823490 rows were processed for file 202207-divvy-tripdata.csv\n",
      "Success. 785934 rows were processed for file 202208-divvy-tripdata.csv\n",
      "Success. 701341 rows were processed for file 202209-divvy-tripdata.csv\n",
      "Success. 558687 rows were processed for file 202210-divvy-tripdata.csv\n",
      "Success. 337737 rows were processed for file 202211-divvy-tripdata.csv\n",
      "Success. 181808 rows were processed for file 202212-divvy-tripdata.csv\n",
      "All records from the csv files have been inserted into the database correctly. \n"
     ]
    }
   ],
   "source": [
    "for i in files:\n",
    "    with open(i, mode=\"r\") as data:\n",
    "        read = csv.reader(data, delimiter=',')\n",
    "        count = 0\n",
    "# row is a list of the actual data, ordered like follows:\n",
    "# ['ride_id': 0 , 'rideable_type': 1, 'started_at': 2, 'ended_at':3, \n",
    "#'start_station_name':4, 'start_station_id':5, 'end_station_name':6, \n",
    "#'end_station_id':7, 'start_lat':8, 'start_lng':9, 'end_lat':10, \n",
    "#'end_lng':11,#'member_casual': 12]\n",
    "        for row in read: \n",
    "# count must be greater than 0, so we don´t insert the headers\n",
    "            if count==0: \n",
    "                count=count+1\n",
    "                #continue\n",
    "# fill table stations, with start_station\n",
    "# the \"or ignore\" allows for only new records to be added\n",
    "            cur.execute('''INSERT OR IGNORE INTO \n",
    "                              stations (station_id, station_name, \n",
    "                                    latitude, longitude)\n",
    "                              VALUES (?, ?, ?, ?)\n",
    "                              ''',(row[5], row[4], row[8], row[9]))\n",
    "# end_station\n",
    "            cur.execute('''INSERT OR IGNORE INTO \n",
    "                              stations (station_id, station_name, \n",
    "                                    latitude, longitude)\n",
    "                              VALUES (?, ?, ?, ?)\n",
    "                              ''',(row[7], row[6], row[10], row[11]))\n",
    "# fill table total with all the months\n",
    "            cur.execute('''INSERT OR IGNORE INTO \n",
    "total (ride_id, rideable_type, started_at, ended_at, start_station_id, \n",
    "       end_station_id, start_lat, start_lng, end_lat, end_lng, membership)\n",
    "                              VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ? )\n",
    "        ''',(row[0], row[1], row[2], row[3],row[5],row[7], row[8], row[9], row[10], row[11], row[12]))\n",
    "            count=count+1\n",
    "#this command saves changes to the db. If you commit through every row,\n",
    "# the whole code might take hours to run\n",
    "        conn.commit()\n",
    "        print (\"Success. \"+str(count)+\" rows were processed for file \"+str(i))\n",
    "conn.close()\n",
    "print(\"All records from the csv files have been inserted into the database correctly. \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1d563b",
   "metadata": {},
   "source": [
    "Now we have every record from the dataset available on the same database, we can more easily analyze the data, as well as screen for incorrect observations. For this second part of exploratory data analysis, it´s very useful to use SQL magic. An added advantage of this method is, when updating the database every command is committed automatically, which isn´t the case using the standard sqlite3 library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bd4b4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you don´t have the library installed:\n",
    "#!pip3 install ipython-sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5ab6667",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql\n",
    "%sql sqlite:///divvy_public.sqlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b064732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * sqlite:///divvy_public.sqlite\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>count(*)</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>5667718</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[(5667718,)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT\n",
    "    count(*)\n",
    "FROM\n",
    "    total;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4087fb",
   "metadata": {},
   "source": [
    "Initially, there are over 5 million rows in the database. Seeing how we have start and end times for each ride, we can try to calculate the duration of each trip. The following cells of code do that, rounded to the nearest minute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04200e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * sqlite:///divvy_public.sqlite\n",
      "5667718 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql \n",
    "UPDATE\n",
    "    total\n",
    "SET\n",
    "    trip_duration=(JULIANDAY(ended_at) - JULIANDAY(started_at))*1440;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2f9de76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * sqlite:///divvy_public.sqlite\n",
      "5667718 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "UPDATE\n",
    "    total\n",
    "SET\n",
    "    trip_duration=ROUND(trip_duration,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0279fead",
   "metadata": {},
   "source": [
    "Using our newly created column, we can start cleaning the database for incorrect entries. For starters, it doesn´t make sense that a record should have a negative trip duration value, or a value that´s too small. For example, it´s more likely a trip duration of one minute was due to a racking or unracking error form a user, than an actual trip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b32f93a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * sqlite:///divvy_public.sqlite\n",
      "161987 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql \n",
    "DELETE FROM\n",
    "    total\n",
    "WHERE\n",
    "    trip_duration<=1;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411a1ec6",
   "metadata": {},
   "source": [
    "Following the same train of thought, what about very short trips that start and end at the same station? We can use an educated guess, and establish that trips of less than 5 minutes and the same start and end locations are also not valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "068cda02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * sqlite:///divvy_public.sqlite\n",
      "146625 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql \n",
    "DELETE FROM\n",
    "    total\n",
    "WHERE\n",
    "    trip_duration<=5\n",
    "AND\n",
    "    start_station_id=end_station_id;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c65373f",
   "metadata": {},
   "source": [
    "Now, we consider the fields of latitude and longitude. As the dataset is from the city of Chicago, which is located at approximately [41.8, -87.6], registers that contain any 0 in their coordinates are also invalid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "800b8803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * sqlite:///divvy_public.sqlite\n",
      "6 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "DELETE FROM\n",
    "  total\n",
    "WHERE\n",
    "  start_lat=0 OR end_lat=0 OR start_lng=0 OR end_lng=0;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120760eb",
   "metadata": {},
   "source": [
    "Now, we can try to calculate the actual distance of each trip. The earth closely resembles a sphere, which is non-euclidean geometry. Therefore, to calculate the shortest distance between two points we use the <i>geodesic</i>. \n",
    "The webpage https://www.geeksforgeeks.org/program-distance-two-points-earth/ offers a great explanation, as well as a code implementation for python of how to calculate a geodesic given start and end coordinates. For this part, we can´t use sql magic, as we need to make the geodesic calculations outside sqlite, in python. This code takes several minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92aa644f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  this cell of code gives us valuable status checks on code that takes some time to run\n",
    "checkpoints=[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "check_status=dict()\n",
    "for i in checkpoints:\n",
    "    check_status[i]=False\n",
    "\n",
    "#if we don´t change the dict status to True, it will print many times \n",
    "# instead of just one\n",
    "def checkpoint_notifications(row_count, total_count):\n",
    "    progress=round((row_count/total_count),1)\n",
    "    if progress in check_status and check_status[progress]==False:\n",
    "        value=(round(progress,1))*100\n",
    "        print (str(value)+\"% completed.\")\n",
    "        check_status[progress]=True\n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b4ecbde0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0% completed.\n",
      "20.0% completed.\n",
      "30.0% completed.\n",
      "40.0% completed.\n",
      "50.0% completed.\n",
      "60.0% completed.\n",
      "70.0% completed.\n",
      "80.0% completed.\n",
      "90.0% completed.\n",
      "Success. 5359100 rows were affected in the database.\n"
     ]
    }
   ],
   "source": [
    "from math import radians, cos, sin, asin, sqrt\n",
    "def distance(lat1, lat2, lon1, lon2):\n",
    "     \n",
    "    # The math module contains a function named\n",
    "    # radians which converts from degrees to radians.\n",
    "    lon1 = radians(lon1)\n",
    "    lon2 = radians(lon2)\n",
    "    lat1 = radians(lat1)\n",
    "    lat2 = radians(lat2)\n",
    "      \n",
    "    # Haversine formula\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
    " \n",
    "    c = 2 * asin(sqrt(a))\n",
    "    \n",
    "    # Radius of earth in kilometers. Use 3956 for miles\n",
    "    r = 6371\n",
    "      \n",
    "    # calculate the distance in km\n",
    "    return(c * r)\n",
    "\n",
    "\n",
    "#start the connection to the database\n",
    "conn = sqlite3.connect('divvy_public.sqlite') \n",
    "cur = conn.cursor()\n",
    "# this statement saves the total rows to the variable total_count\n",
    "cur.execute('''SELECT COUNT(*) FROM total;''')\n",
    "total_count=cur.fetchone()[0]\n",
    "\n",
    "# with this statement, I can obtain the inputs for the distance function\n",
    "cur.execute('''SELECT start_lat, end_lat, start_lng, end_lng, ride_id\n",
    "            FROM total;\n",
    "                      ''')\n",
    "# cur.fetchall is a list with the elements I asked, for every row\n",
    "table=cur.fetchall()\n",
    "row_count=0\n",
    "for row in table:\n",
    "# make the calculation. If it´s unsuccesful for some reason, return a 0\n",
    "# for distance. We can clean those values later directly in the db\n",
    "    try:\n",
    "        lat1= float(row[0])\n",
    "        lat2=float(row[1])\n",
    "        lon1=float(row[2])\n",
    "        lon2=float(row[3])\n",
    "        dist=round(distance(lat1,lat2,lon1,lon2),2)\n",
    "    except:\n",
    "        dist=0\n",
    "    cur.execute('''UPDATE total SET trip_distance \n",
    "                =? WHERE ride_id=?''', (dist,row[4]))\n",
    "    row_count=row_count+1\n",
    "# call the function we defiend for progress notifications\n",
    "    checkpoint_notifications(row_count, total_count)\n",
    "\n",
    "conn.commit()\n",
    "print(\"Success. \"+str(total_count)+ \" rows were affected in the database.\")\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e765dc",
   "metadata": {},
   "source": [
    "With this new field, we can introduce additional data cleaning queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03dd9c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * sqlite:///divvy_public.sqlite\n",
      "13083 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "DELETE FROM\n",
    "    total\n",
    "WHERE\n",
    "    trip_distance=0 AND \n",
    "        start_station_id !=end_station_id;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143a9a29",
   "metadata": {},
   "source": [
    "We now wish to work on the stations table. It would be useful for future analysis to know how many times each station was visited. Knowing the most visited stations can also aid a marketing team in deciding where it is best to place advertising for casual users to become members, and increase customer retention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e8a0f458",
   "metadata": {},
   "outputs": [],
   "source": [
    "#start the connection to the database\n",
    "conn = sqlite3.connect('divvy_public.sqlite') \n",
    "cur = conn.cursor()\n",
    "# get the number of columns\n",
    "cur.execute('''SELECT COUNT(*) FROM total;''')\n",
    "total_count=cur.fetchone()[0]\n",
    "\n",
    "# reset the count, in case there´s already values\n",
    "cur.execute('''UPDATE stations\n",
    "                SET times_visited=0;''')\n",
    "\n",
    "\n",
    "# run a query to get all start_station ids from total\n",
    "cur.execute('''SELECT start_station_id, end_station_id\n",
    "                FROM total;''')\n",
    "data1=cur.fetchall()\n",
    "row_count=0\n",
    "for row in data1:\n",
    "    id1=str(row[0])\n",
    "    id2=str(row[1])    \n",
    "#update count for every ocurrence of start_station      \n",
    "    cur.execute('''UPDATE stations\n",
    "                    SET times_visited=times_visited+1\n",
    "                    WHERE station_id= ?;''', [id1])\n",
    "# the same, but also for the end_station\n",
    "    cur.execute('''UPDATE stations\n",
    "                     SET times_visited=times_visited+1\n",
    "                     WHERE station_id= ?;''', [id2])\n",
    "    row_count=row_count+1\n",
    "# call the function we defiend for progress notifications\n",
    "    checkpoint_notifications(row_count, total_count)\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80261e1f",
   "metadata": {},
   "source": [
    "We run additional data cleaning, taking advantage of this newly-created field. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b293fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * sqlite:///divvy_public.sqlite\n",
      "1325 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "DELETE FROM\n",
    "    stations\n",
    "WHERE\n",
    "    times_visited=0;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f484aee1",
   "metadata": {},
   "source": [
    "<h3>Step 4: Finding insights (modeling)</h3>\n",
    "<p></p>\n",
    "Now the data is cleaned, we can look to derive insights from it, in accordance with the business goals of this sample case. We can start by identifying the 10 most popular trips from registered stations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ccadb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * sqlite:///divvy_public.sqlite\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS \n",
    "    top_trips;\n",
    "CREATE TABLE \n",
    "    top_trips AS\n",
    "SELECT\n",
    "    start_station_id, end_station_id, COUNT(*) AS trip_count\n",
    "FROM\n",
    "    total\n",
    "WHERE\n",
    "    LENGTH(start_station_id)>1 AND LENGTH(end_station_id)>1\n",
    "GROUP BY\n",
    "    start_station_id, end_station_id\n",
    "ORDER BY \n",
    "    trip_count DESC\n",
    "LIMIT 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c43448",
   "metadata": {},
   "source": [
    "We now match the station id to its actual name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948e9168",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "ALTER TABLE \n",
    "    top_trips\n",
    "ADD \n",
    "    start_station_name TINYTEXT;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad5e5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "ALTER TABLE \n",
    "    top_trips\n",
    "ADD \n",
    "    end_station_name TINYTEXT;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084d7667",
   "metadata": {},
   "source": [
    "For matching the name to the id, we can use placeholders in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdb77bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('divvy_public.sqlite') \n",
    "cur = conn.cursor()\n",
    "cur.execute('''SELECT start_station_id,\n",
    "                end_station_id \n",
    "                FROM top_trips;''')\n",
    "data=cur.fetchall()\n",
    "for row in data:\n",
    "    start_id=row[0]\n",
    "    end_id=row[1]\n",
    "#  find the station name corresponding to the id in table stations,\n",
    "#  then insert it into top_trips\n",
    "    cur.execute('''SELECT station_name\n",
    "                    FROM stations\n",
    "                    WHERE station_id= ?;''',[start_id])\n",
    "    start_name=cur.fetchone()[0]\n",
    "    cur.execute('''UPDATE top_trips\n",
    "                    SET start_station_name= ?\n",
    "                    WHERE start_station_id=?\n",
    "                ;''',(start_name,start_id))\n",
    "#  the same, but for end_station\n",
    "    cur.execute('''SELECT station_name\n",
    "                    FROM stations\n",
    "                    WHERE station_id= ?;''',[end_id])\n",
    "    end_name=cur.fetchone()[0]\n",
    "    cur.execute('''UPDATE top_trips\n",
    "                    SET end_station_name= ?\n",
    "                    WHERE end_station_id=?\n",
    "                ;''',(end_name,end_id))\n",
    "    conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff51bbbb",
   "metadata": {},
   "source": [
    "We now check for a preview of this newly-created table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ef7e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * FROM \n",
    "    top_trips;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b701c82",
   "metadata": {},
   "source": [
    "We can also check the stations table, to gather the most visited places:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5572719",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT*FROM\n",
    "    stations\n",
    "WHERE\n",
    "    LENGTH(station_name)>1\n",
    "ORDER BY \n",
    "    times_visited DESC\n",
    "LIMIT 10;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c289451",
   "metadata": {},
   "source": [
    "We now know the Streeter Dr & Grand Ave station is by far the most popular divvy bike share station, and possibly where future advertising efforts directed to casual members should be concentrated. But what about casual users and paid members? What differentiates them from each other?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d3ab64",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "SELECT* \n",
    "FROM \n",
    "    total\n",
    "LIMIT 5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62299809",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT\n",
    "    membership, COUNT(*) AS \"total trips\", AVG(trip_duration), AVG(trip_distance)\n",
    "FROM \n",
    "    total\n",
    "GROUP BY\n",
    "    membership;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469aec9c",
   "metadata": {},
   "source": [
    "We can observe that members take more trips in total than casual users. They also take similar distance trips, but in much less time. A possible explanation for this, is that members need more frequent use of the bikes for their day-to-day endeavours, therefore they take more trips than casual users. They also take less time, because their trips are more likely to be previously planned. Casual users, on the other hand, may use the bikes on a more \"ad hoc\" basis, involving less planning and less bike use, and take more time to complete their trips. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a937f62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "SELECT \n",
    "    rideable_type, membership, count(*) AS \"total trips\"\n",
    "FROM \n",
    "    total\n",
    "GROUP BY \n",
    "    rideable_type, membership"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5968bb",
   "metadata": {},
   "source": [
    "We can now observe casual users tend to use more electric bikes, whereas members tend to prefer classic bikes. Again, we can try to explain this by considering casual users might need the rental service for an unplanned event, therefore appreciate more electric bikes for getting to their destination faster. \n",
    "<p></p>\n",
    "Now, we have gathered sufficient information on the differences between casuals and members, and can proceed to share our findings. These can be graphically illustrated using pandas dataframes and plotting libraries like seaborn or matplotlib, but on this occation we choose to employ Tableau Public, a very popular business analytics tool with a user-friendly interface, capable of producing stunning visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffc0b56",
   "metadata": {},
   "source": [
    "You can check the visualization results at https://public.tableau.com/app/profile/luis.gonzalez6272/viz/Divvypublicdata2022/top_stations, or continue on this folder for the complete results. \n",
    "\n",
    "<p>\n",
    "Thank you for your interest in this project :)\n",
    "    </p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
